2022-11-09 04:09:25,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = nura-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.3.4
STARTUP_MSG:   classpath = /home/nura/Desktop/hadoop/etc/hadoop:/home/nura/Desktop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z
STARTUP_MSG:   java = 1.8.0_351
************************************************************/
2022-11-09 04:09:25,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-11-09 04:09:30,867 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-nura/dfs/data
2022-11-09 04:09:32,263 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2022-11-09 04:09:33,737 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-11-09 04:09:33,737 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-11-09 04:09:40,304 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-11-09 04:09:40,575 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-11-09 04:09:40,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is nura-VirtualBox
2022-11-09 04:09:40,693 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-11-09 04:09:40,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-11-09 04:09:41,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2022-11-09 04:09:41,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2022-11-09 04:09:41,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2022-11-09 04:09:41,740 INFO org.eclipse.jetty.util.log: Logging initialized @23824ms to org.eclipse.jetty.util.log.Slf4jLog
2022-11-09 04:09:44,355 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/nura/hadoop-http-auth-signature-secret
2022-11-09 04:09:44,520 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-11-09 04:09:44,674 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-11-09 04:09:44,724 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-11-09 04:09:44,724 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-11-09 04:09:44,724 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-11-09 04:09:45,137 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45555
2022-11-09 04:09:45,193 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_351-b10
2022-11-09 04:09:45,530 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2022-11-09 04:09:45,530 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2022-11-09 04:09:45,544 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2022-11-09 04:09:45,684 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6bca7e0d{logs,/logs,file:///home/nura/Desktop/hadoop/logs/,AVAILABLE}
2022-11-09 04:09:45,684 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@30af5b6b{static,/static,file:///home/nura/Desktop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2022-11-09 04:09:46,460 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@25a6944c{datanode,/,file:///home/nura/Desktop/hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/home/nura/Desktop/hadoop/share/hadoop/hdfs/webapps/datanode}
2022-11-09 04:09:46,556 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@2c1156a7{HTTP/1.1, (http/1.1)}{localhost:45555}
2022-11-09 04:09:46,563 INFO org.eclipse.jetty.server.Server: Started @28640ms
2022-11-09 04:09:48,051 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2022-11-09 04:09:49,151 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2022-11-09 04:09:49,226 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-11-09 04:09:49,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = nura
2022-11-09 04:09:49,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-11-09 04:09:50,293 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-11-09 04:09:50,531 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2022-11-09 04:09:53,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2022-11-09 04:09:53,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-11-09 04:09:53,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-11-09 04:09:53,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-11-09 04:09:53,963 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-11-09 04:09:53,956 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2022-11-09 04:09:56,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:09:57,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:09:58,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:09:59,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:00,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:01,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:02,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:03,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:04,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:05,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:05,257 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:10:11,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:12,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:13,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:14,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:15,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:16,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:17,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:18,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:19,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:20,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:20,351 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:10:26,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:27,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:28,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:29,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:30,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:31,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:32,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:33,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:34,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:35,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:35,386 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:10:41,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:42,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:43,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:44,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:45,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:46,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:47,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:48,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:49,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:50,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:50,408 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:10:56,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:57,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:58,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:10:59,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:00,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:01,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:02,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:03,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:04,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:05,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:05,429 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:11:11,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:12,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:13,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:14,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:15,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:16,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:17,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:18,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:19,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:20,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:20,447 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:11:26,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:27,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:28,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:29,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:30,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:31,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:32,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:33,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:34,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:35,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:11:35,461 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:11:36,256 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2022-11-09 04:11:36,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at nura-VirtualBox/127.0.1.1
************************************************************/
2022-11-09 04:12:34,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = nura-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.3.4
STARTUP_MSG:   classpath = /home/nura/Desktop/hadoop/etc/hadoop:/home/nura/Desktop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/home/nura/Desktop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z
STARTUP_MSG:   java = 1.8.0_351
************************************************************/
2022-11-09 04:12:34,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-11-09 04:12:39,106 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-nura/dfs/data
2022-11-09 04:12:40,462 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2022-11-09 04:12:41,536 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-11-09 04:12:41,537 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-11-09 04:12:47,083 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-11-09 04:12:47,383 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-11-09 04:12:47,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is nura-VirtualBox
2022-11-09 04:12:47,517 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-11-09 04:12:47,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-11-09 04:12:47,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2022-11-09 04:12:47,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2022-11-09 04:12:47,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2022-11-09 04:12:48,139 INFO org.eclipse.jetty.util.log: Logging initialized @18393ms to org.eclipse.jetty.util.log.Slf4jLog
2022-11-09 04:12:49,840 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/nura/hadoop-http-auth-signature-secret
2022-11-09 04:12:49,936 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-11-09 04:12:50,075 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-11-09 04:12:50,078 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-11-09 04:12:50,078 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-11-09 04:12:50,078 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-11-09 04:12:50,412 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42123
2022-11-09 04:12:50,452 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_351-b10
2022-11-09 04:12:50,715 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2022-11-09 04:12:50,715 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2022-11-09 04:12:50,717 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2022-11-09 04:12:50,854 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f132176{logs,/logs,file:///home/nura/Desktop/hadoop/logs/,AVAILABLE}
2022-11-09 04:12:50,854 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@8ad6665{static,/static,file:///home/nura/Desktop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2022-11-09 04:12:51,389 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@158a3b2e{datanode,/,file:///home/nura/Desktop/hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/home/nura/Desktop/hadoop/share/hadoop/hdfs/webapps/datanode}
2022-11-09 04:12:51,513 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@38831718{HTTP/1.1, (http/1.1)}{localhost:42123}
2022-11-09 04:12:51,513 INFO org.eclipse.jetty.server.Server: Started @21767ms
2022-11-09 04:12:52,538 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2022-11-09 04:12:53,301 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2022-11-09 04:12:53,384 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-11-09 04:12:53,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = nura
2022-11-09 04:12:53,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-11-09 04:12:53,851 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-11-09 04:12:53,964 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2022-11-09 04:12:56,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2022-11-09 04:12:56,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-11-09 04:12:56,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-11-09 04:12:56,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-11-09 04:12:57,078 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-11-09 04:12:57,079 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2022-11-09 04:12:58,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:12:59,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:00,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:01,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:02,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:03,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:04,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:05,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:06,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:07,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:07,792 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:13:13,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:14,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:15,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:16,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:17,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:18,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:19,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:20,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:21,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:22,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:22,821 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:13:28,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:29,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:30,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:31,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:32,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:33,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:34,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:35,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:36,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:37,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:37,842 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:13:43,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:44,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:45,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:46,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:47,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:48,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:49,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:50,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:51,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:52,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:52,852 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:13:58,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:13:59,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:00,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:01,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:02,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:03,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:04,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:05,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:06,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:07,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:07,862 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:14:13,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:14,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:15,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:16,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:17,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:18,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:19,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:20,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:21,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:22,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:22,872 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:14:28,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:29,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:30,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:31,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:32,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:33,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:34,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:35,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:36,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:37,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-11-09 04:14:37,892 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2022-11-09 04:14:49,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-11-09 04:14:49,398 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-11-09 04:14:49,448 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-nura/dfs/data/in_use.lock acquired by nodename 23376@nura-VirtualBox
2022-11-09 04:14:49,451 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/tmp/hadoop-nura/dfs/data is not formatted for namespace 1323108717. Formatting...
2022-11-09 04:14:49,463 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-2e9b5815-6ab4-4069-afc8-61d9bfb58f1c for directory /tmp/hadoop-nura/dfs/data 
2022-11-09 04:14:49,721 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-604276166-127.0.1.1-1667949245985
2022-11-09 04:14:49,722 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-nura/dfs/data/current/BP-604276166-127.0.1.1-1667949245985
2022-11-09 04:14:49,732 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/tmp/hadoop-nura/dfs/data and block pool id BP-604276166-127.0.1.1-1667949245985 is not formatted. Formatting ...
2022-11-09 04:14:49,733 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-604276166-127.0.1.1-1667949245985 directory /tmp/hadoop-nura/dfs/data/current/BP-604276166-127.0.1.1-1667949245985/current
2022-11-09 04:14:49,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1323108717;bpid=BP-604276166-127.0.1.1-1667949245985;lv=-57;nsInfo=lv=-66;cid=CID-da400fdf-dc1b-479d-8faa-03197739b657;nsid=1323108717;c=1667949245985;bpid=BP-604276166-127.0.1.1-1667949245985;dnuuid=null
2022-11-09 04:14:49,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 715a9700-186a-4cb4-929d-1565a8b5c031
2022-11-09 04:14:49,799 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2022-11-09 04:14:50,380 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-2e9b5815-6ab4-4069-afc8-61d9bfb58f1c
2022-11-09 04:14:50,381 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/tmp/hadoop-nura/dfs/data, StorageType: DISK
2022-11-09 04:14:50,387 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2022-11-09 04:14:50,415 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-11-09 04:14:50,457 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-604276166-127.0.1.1-1667949245985
2022-11-09 04:14:50,465 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-604276166-127.0.1.1-1667949245985 on volume /tmp/hadoop-nura/dfs/data...
2022-11-09 04:14:50,512 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /tmp/hadoop-nura/dfs/data/current/BP-604276166-127.0.1.1-1667949245985/current, will proceed with Du for space computation calculation, 
2022-11-09 04:14:50,665 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-604276166-127.0.1.1-1667949245985 on /tmp/hadoop-nura/dfs/data: 199ms
2022-11-09 04:14:50,665 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-604276166-127.0.1.1-1667949245985: 201ms
2022-11-09 04:14:50,670 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-604276166-127.0.1.1-1667949245985 on volume /tmp/hadoop-nura/dfs/data...
2022-11-09 04:14:50,678 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /tmp/hadoop-nura/dfs/data/current/BP-604276166-127.0.1.1-1667949245985/current/replicas doesn't exist 
2022-11-09 04:14:50,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-604276166-127.0.1.1-1667949245985 on volume /tmp/hadoop-nura/dfs/data: 26ms
2022-11-09 04:14:50,698 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-604276166-127.0.1.1-1667949245985: 33ms
2022-11-09 04:14:50,704 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /tmp/hadoop-nura/dfs/data
2022-11-09 04:14:50,755 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /tmp/hadoop-nura/dfs/data
2022-11-09 04:14:50,773 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-604276166-127.0.1.1-1667949245985 on volume /tmp/hadoop-nura/dfs/data
2022-11-09 04:14:50,785 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-nura/dfs/data, DS-2e9b5815-6ab4-4069-afc8-61d9bfb58f1c): finished scanning block pool BP-604276166-127.0.1.1-1667949245985
2022-11-09 04:14:50,792 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2022-11-09 04:14:50,796 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 16823648ms with interval of 21600000ms and throttle limit of -1ms/s
2022-11-09 04:14:50,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-604276166-127.0.1.1-1667949245985 (Datanode Uuid 715a9700-186a-4cb4-929d-1565a8b5c031) service to localhost/127.0.0.1:9000 beginning handshake with NN
2022-11-09 04:14:50,932 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-nura/dfs/data, DS-2e9b5815-6ab4-4069-afc8-61d9bfb58f1c): no suitable block pools found to scan.  Waiting 1814399841 ms.
2022-11-09 04:14:51,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-604276166-127.0.1.1-1667949245985 (Datanode Uuid 715a9700-186a-4cb4-929d-1565a8b5c031) service to localhost/127.0.0.1:9000 successfully registered with NN
2022-11-09 04:14:51,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2022-11-09 04:14:52,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x703cdf627f3c1549 with lease ID 0xd9367d875ace094e to namenode: localhost/127.0.0.1:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 16 msecs to generate and 293 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-11-09 04:14:52,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-604276166-127.0.1.1-1667949245985
2022-11-09 04:15:56,963 INFO datanode.webhdfs: 127.0.0.1 OPTIONS /webhdfs/v1/user/nura/ipaddress/input/ip_large.txt?op=CREATE&namenoderpcaddress=localhost:9000&createflag=&createparent=true&overwrite=false 200
2022-11-09 04:15:58,998 INFO datanode.webhdfs: 127.0.0.1 PUT /webhdfs/v1/user/nura/ipaddress/input/ip_large.txt?op=CREATE&namenoderpcaddress=localhost:9000&createflag=&createparent=true&overwrite=false 201
2022-11-09 04:16:00,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-604276166-127.0.1.1-1667949245985:blk_1073741825_1001 src: /127.0.0.1:36262 dest: /127.0.0.1:9866
2022-11-09 04:16:01,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:36262, dest: /127.0.0.1:9866, bytes: 14282651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-86593514_70, offset: 0, srvID: 715a9700-186a-4cb4-929d-1565a8b5c031, blockid: BP-604276166-127.0.1.1-1667949245985:blk_1073741825_1001, duration(ns): 514253645
2022-11-09 04:16:01,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-604276166-127.0.1.1-1667949245985:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2022-11-09 04:16:09,788 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 14282651
  getBytesOnDisk()  = 14282651
  getVisibleLength()= 14282651
  getVolume()       = /tmp/hadoop-nura/dfs/data
  getBlockURI()     = file:/tmp/hadoop-nura/dfs/data/current/BP-604276166-127.0.1.1-1667949245985/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2022-11-09 04:16:09,794 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-604276166-127.0.1.1-1667949245985 blk_1073741825_1001 URI file:/tmp/hadoop-nura/dfs/data/current/BP-604276166-127.0.1.1-1667949245985/current/finalized/subdir0/subdir0/blk_1073741825
2022-11-09 04:21:09,712 INFO datanode.webhdfs: 127.0.0.1 OPTIONS /webhdfs/v1/user/nura/ipaddress/input/ip_large2.txt?op=CREATE&namenoderpcaddress=localhost:9000&createflag=&createparent=true&overwrite=false 200
2022-11-09 04:21:10,182 INFO datanode.webhdfs: 127.0.0.1 PUT /webhdfs/v1/user/nura/ipaddress/input/ip_large.txt?op=CREATE&namenoderpcaddress=localhost:9000&createflag=&createparent=true&overwrite=false 201
2022-11-09 04:21:10,497 INFO datanode.webhdfs: 127.0.0.1 PUT /webhdfs/v1/user/nura/ipaddress/input/ip_large2.txt?op=CREATE&namenoderpcaddress=localhost:9000&createflag=&createparent=true&overwrite=false 201
2022-11-09 04:21:10,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-604276166-127.0.1.1-1667949245985:blk_1073741826_1002 src: /127.0.0.1:60546 dest: /127.0.0.1:9866
2022-11-09 04:21:11,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-604276166-127.0.1.1-1667949245985:blk_1073741827_1003 src: /127.0.0.1:60560 dest: /127.0.0.1:9866
2022-11-09 04:21:12,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60546, dest: /127.0.0.1:9866, bytes: 14282651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1816323496_70, offset: 0, srvID: 715a9700-186a-4cb4-929d-1565a8b5c031, blockid: BP-604276166-127.0.1.1-1667949245985:blk_1073741826_1002, duration(ns): 1477411556
2022-11-09 04:21:12,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-604276166-127.0.1.1-1667949245985:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2022-11-09 04:21:13,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60560, dest: /127.0.0.1:9866, bytes: 14282651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_720241019_69, offset: 0, srvID: 715a9700-186a-4cb4-929d-1565a8b5c031, blockid: BP-604276166-127.0.1.1-1667949245985:blk_1073741827_1003, duration(ns): 1678866115
2022-11-09 04:21:13,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-604276166-127.0.1.1-1667949245985:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2022-11-09 04:23:20,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-604276166-127.0.1.1-1667949245985:blk_1073741828_1004 src: /127.0.0.1:56952 dest: /127.0.0.1:9866
2022-11-09 04:23:27,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56952, dest: /127.0.0.1:9866, bytes: 16278339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1334963316_1, offset: 0, srvID: 715a9700-186a-4cb4-929d-1565a8b5c031, blockid: BP-604276166-127.0.1.1-1667949245985:blk_1073741828_1004, duration(ns): 6650340597
2022-11-09 04:23:27,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-604276166-127.0.1.1-1667949245985:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2022-11-09 04:25:35,450 INFO datanode.webhdfs: 127.0.0.1 GET /webhdfs/v1/user/nura/ipaddress/output/part-r-00000?op=OPEN&namenoderpcaddress=localhost:9000&offset=0 200
2022-11-09 04:27:27,294 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2022-11-09 04:27:27,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at nura-VirtualBox/127.0.1.1
************************************************************/
2022-11-09 04:27:27,893 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "nura-VirtualBox/127.0.1.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:543)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:677)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:879)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
